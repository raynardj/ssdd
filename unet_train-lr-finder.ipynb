{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "### 400 * 4 operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA = DATA = Path('/home/paperspace/ssdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 6\n",
    "#LR = 5e-3\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = \"senet154\"\n",
    "REMARK = \"_\"\n",
    "THRESHOLD = 0.5\n",
    "CUT_HORI = True\n",
    "\n",
    "MODEL_PTH = \"ssdd_%s_b%s%s.pth\"%(MODEL_NAME,BS,REMARK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choices of model names\n",
    "\n",
    "### VGG\n",
    "vgg11, vgg13, vgg16, vgg19, vgg11bn, vgg13bn, vgg16bn, vgg19bn,\n",
    "### Densenet\n",
    "densenet121, densenet169, densenet201, densenet161, dpn68, dpn98, dpn131,\n",
    "### Resnet\n",
    "inceptionresnetv2,\n",
    "resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "resnext50_32x4d, resnext101_32x8d,\n",
    "### SeNet\n",
    "se_resnet50, se_resnet101, se_resnet152,\n",
    "se_resnext50_32x4d, se_resnext101_32x4d,\n",
    "senet154,\n",
    "#### EfficientNet\n",
    "efficientnet-b0, efficientnet-b1, efficientnet-b2, efficientnet-b3, efficientnet-b4, efficientnet-b5, efficientnet-b6, efficientnet-b7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from albumentations import (HorizontalFlip, RGBShift, ElasticTransform, GridDistortion,RandomBrightness ,ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    Numpy image to run length encoding\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image'] # 1x256x1600\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "        \n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.5), # only horizontal flip as of now\n",
    "                RGBShift(),\n",
    "                ElasticTransform(),\n",
    "                GridDistortion(), \n",
    "                RandomBrightness(),\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=BS,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice and IoU metric implementations, metric logger for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "def metric(probability, truth, threshold=THRESHOLD, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.dice_pos_scores.append(dice_pos)\n",
    "        self.dice_neg_scores.append(dice_neg)\n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        dice_neg = np.mean(self.dice_neg_scores)\n",
    "        dice_pos = np.mean(self.dice_pos_scores)\n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        return dices, iou\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
    "    return dice, iou\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "    return ious if ious else [1]\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou\n",
    "\n",
    "def cutHorizontal(x):\n",
    "    return torch.cat(list(x[...,i*400:(i+1)*400] for i in range(4)), dim=0)\n",
    "\n",
    "def to416(x):\n",
    "    size = list(x.size())\n",
    "    size[-1]=416\n",
    "    new = torch.zeros(size)\n",
    "    new[...,8:-8] = x\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.FPN(MODEL_NAME, encoder_weights=\"imagenet\", classes=4, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = provider(\n",
    "                data_folder= DATA,\n",
    "                df_path= DATA/'train.csv',\n",
    "                phase='train',\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=6,\n",
    "                num_workers=6,\n",
    "            )\n",
    "\n",
    "valloader = provider(\n",
    "                data_folder= DATA,\n",
    "                df_path= DATA/'train.csv',\n",
    "                phase='val',\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=6,\n",
    "                num_workers=6,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f911e1d4364502b9dabf511cb45be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "#model = smp.Unet(\"efficientnet-b5\", encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-3)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(trainloader, end_lr=10, num_iter=200, step_mode=\"exp\")\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
