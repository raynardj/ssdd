{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet/FPN Fastai\n",
    "\n",
    "* The entire operation into fastai lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA = DATA = Path('/home/paperspace/ssdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2\n",
    "LR_MIN = 1e-4\n",
    "LR_MAX = 3e-4\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = \"efficientnet-b5\"\n",
    "REMARK = \"_\"\n",
    "THRESHOLD = 0.5\n",
    "# cut to 400*4?\n",
    "CUT_HORI = False \n",
    "FP16 = True\n",
    "\n",
    "MODEL_PTH = \"ssdd_%s_b%s%s.pth\"%(MODEL_NAME,BS,REMARK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choices of model names\n",
    "\n",
    "### VGG\n",
    "vgg11, vgg13, vgg16, vgg19, vgg11bn, vgg13bn, vgg16bn, vgg19bn,\n",
    "### Densenet\n",
    "densenet121, densenet169, densenet201, densenet161, dpn68, dpn98, dpn131,\n",
    "### Resnet\n",
    "inceptionresnetv2,\n",
    "resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "resnext50_32x4d, resnext101_32x8d,\n",
    "### SeNet\n",
    "se_resnet50, se_resnet101, se_resnet152,\n",
    "se_resnext50_32x4d, se_resnext101_32x4d,\n",
    "senet154,\n",
    "#### EfficientNet\n",
    "efficientnet-b0, efficientnet-b1, efficientnet-b2, efficientnet-b3, efficientnet-b4, efficientnet-b5, efficientnet-b6, efficientnet-b7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from albumentations import (HorizontalFlip, RGBShift, ElasticTransform, GridDistortion,RandomBrightness ,ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "from onecyclelr import OneCycleLR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    Numpy image to run length encoding\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cutHorizontal(x):\n",
    "    return torch.cat(list(x[...,i*400:(i+1)*400] for i in range(4)), dim=0)\n",
    "\n",
    "def to416(x):\n",
    "    size = list(x.size())\n",
    "    size[-1]=416\n",
    "    new = torch.zeros(size)\n",
    "    new[...,8:-8] = x\n",
    "    return new\n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image'] # 1x256x1600\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "        \n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.5), # only horizontal flip as of now\n",
    "                ShiftScaleRotate(scale_limit=0, rotate_limit=0),\n",
    "                ElasticTransform(),\n",
    "                GridDistortion(), \n",
    "                RandomBrightness(),\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=BS,\n",
    "    num_workers=8,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "#     df = train_df if phase == \"train\" else val_df\n",
    "    train_ds = SteelDataset(train_df, data_folder, mean, std, \"train\")\n",
    "    val_ds  =SteelDataset(val_df, data_folder, mean,std, \"val\")\n",
    "    databunch = DataBunch.create(train_ds,val_ds,path = data_folder,bs=BS,num_workers=num_workers)\n",
    "\n",
    "    return databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = provider(\n",
    "    data_folder=DATA,\n",
    "                df_path=DATA/\"train.csv\",\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=BS,\n",
    "                num_workers=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 256, 1600]), torch.Size([2, 4, 256, 1600]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(),y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice and IoU metric implementations, metric logger for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricSeg(probability, truth, threshold=THRESHOLD, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    probability = torch.sigmoid(probability)\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > threshold).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class dices(LearnerCallback):\n",
    "    _order = -20 # Needs to run before the recorder, very CRITICAL step\n",
    "    def __init__(self,learn):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_train_begin(self,**kwargs):\n",
    "        self.learn.recorder.add_metric_names(['dice','dice_neg','dice_pos','num_neg','num_pos'])\n",
    "        \n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        self.ttl_dice = []\n",
    "        self.ttl_dice_neg = []\n",
    "        self.ttl_dice_pos = []\n",
    "        self.ttl_num_neg = []\n",
    "        self.ttl_num_pos = []\n",
    "        self.ttl_lists = [self.ttl_dice,self.ttl_dice_neg,self.ttl_dice_pos,self.ttl_num_neg,self.ttl_num_pos]\n",
    "    \n",
    "    def on_batch_end(self,last_output,last_target,**kwargs):\n",
    "        dice, dice_neg, dice_pos, num_neg, num_pos = metricSeg(last_output,last_target)\n",
    "        self.ttl_dice.append(dice)\n",
    "        self.ttl_dice_neg.append(dice_neg)\n",
    "        self.ttl_dice_pos.append(dice_pos)\n",
    "        self.ttl_num_neg.append(num_neg)\n",
    "        self.ttl_num_pos.append(num_pos)\n",
    "    \n",
    "    def on_epoch_end(self,last_metrics,**kwargs):\n",
    "        extras = [sum(i)/float(len(i)) for i in self.ttl_lists]\n",
    "#         print(extras)\n",
    "        return add_metrics(last_metrics, extras)\n",
    "    \n",
    "class cutHorizonCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target,**kwargs):\n",
    "        last_input = to416(cutHorizontal(last_input))\n",
    "        last_target = to416(cutHorizontal(last_target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.FPN(MODEL_NAME, encoder_weights=\"imagenet\", classes=4, activation=None).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model, metrics = [],loss_func = nn.BCEWithLogitsLoss(),callback_fns = dices).to_fp16()\n",
    "learn.path = Path(\"./fastai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>dice_neg</th>\n",
       "      <th>dice_pos</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.529552</td>\n",
       "      <td>0.293241</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068948</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396419</td>\n",
       "      <td>0.106751</td>\n",
       "      <td>0.027302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255970</td>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059673</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>0.056916</td>\n",
       "      <td>0.113575</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.086607</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.170024</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153370</td>\n",
       "      <td>0.056740</td>\n",
       "      <td>0.218936</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.149308</td>\n",
       "      <td>0.063874</td>\n",
       "      <td>0.226357</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.135874</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.378654</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.280427</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.249737</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.220313</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.117514</td>\n",
       "      <td>0.075583</td>\n",
       "      <td>0.334497</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.107423</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>0.451408</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.180945</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.101766</td>\n",
       "      <td>0.047080</td>\n",
       "      <td>0.364866</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.101008</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.051233</td>\n",
       "      <td>0.305048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.137742</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.415723</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250998</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.088936</td>\n",
       "      <td>0.125340</td>\n",
       "      <td>0.432139</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.291848</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.082017</td>\n",
       "      <td>0.078123</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.203445</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.080162</td>\n",
       "      <td>0.406869</td>\n",
       "      <td>0.271734</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.093249</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.133408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182904</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.240137</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.068068</td>\n",
       "      <td>0.152746</td>\n",
       "      <td>0.320642</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.331285</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.063501</td>\n",
       "      <td>0.053692</td>\n",
       "      <td>0.403145</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.366709</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.058790</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.423405</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.439332</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.031060</td>\n",
       "      <td>0.490098</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.380852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.343516</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.218767</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.480668</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.485105</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.383524</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.412526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.043099</td>\n",
       "      <td>0.375968</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.039034</td>\n",
       "      <td>0.041580</td>\n",
       "      <td>0.448527</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.315383</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.428918</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.363430</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.034994</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.462638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.373866</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>0.035030</td>\n",
       "      <td>0.434768</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.493265</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.031194</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.475214</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.039585</td>\n",
       "      <td>0.470114</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.405783</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.425409</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.419064</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.051828</td>\n",
       "      <td>0.511709</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>0.055257</td>\n",
       "      <td>0.357522</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.396601</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.053681</td>\n",
       "      <td>0.399694</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.323160</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.022112</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.472859</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.414433</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>0.050291</td>\n",
       "      <td>0.429517</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.271880</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.501938</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.319707</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>0.047130</td>\n",
       "      <td>0.533160</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505684</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.046304</td>\n",
       "      <td>0.518991</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.573368</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.046175</td>\n",
       "      <td>0.403364</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.459086</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.016986</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>0.441587</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.443979</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>0.045644</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.346317</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.489997</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.436179</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>0.451492</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.452976</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.045718</td>\n",
       "      <td>0.420893</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.346113</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.045713</td>\n",
       "      <td>0.448725</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.370877</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(50,1e-3,callbacks=[\n",
    "#                                         dices(learn),\n",
    "                                       cutHorizonCallback(),\n",
    "                                       SaveModelCallback(learn, every='epoch', monitor='loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
